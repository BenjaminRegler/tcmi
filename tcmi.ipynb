{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "<div id=\"teaser\" style=' background-position:  right center; background-size: 00px; background-repeat: no-repeat; \n",
    "    padding-top: 20px;\n",
    "    padding-right: 10px;\n",
    "    padding-bottom: 170px;\n",
    "    padding-left: 10px;\n",
    "    border-bottom: 14px double #333;\n",
    "    border-top: 14px double #333;' > \n",
    "\n",
    "   \n",
    "   <div style=\"text-align:center\">\n",
    "    <b><font size=\"6.4\">Total cumulative mutual information</font></b>    \n",
    "  </div>\n",
    "    \n",
    "<p>\n",
    " created by:\n",
    " Benjamin Regler<sup>1</sup>, \n",
    " Matthias Scheffler<sup>1</sup>,\n",
    " and Luca M. Ghiringhelli<sup> 1</sup> <br><br>\n",
    "<sup>1</sup> Fritz Haber Institute of the Max Planck Society, Faradayweg 4-6, D-14195 Berlin, Germany <br>\n",
    "<span class=\"nomad--last-updated\" data-version=\"v1.1.0\">[Last updated: February 28, 2022]</span>\n",
    "</p>\n",
    "  \n",
    "<div> \n",
    "    <img style=\"float: left;\" src=\"assets/logo-mpg.png\" width=\"200\"> \n",
    "    <img style=\"float: right;\" src=\"assets/logo-nomad.png\" width=\"250\">\n",
    "</div>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T16:58:13.885666Z",
     "start_time": "2020-01-13T16:58:13.881334Z"
    }
   },
   "source": [
    "This interactive notebook introduces the concepts and the original implementation of total cumulative mutual information (TCMI) to reproduce the main results presented in the publication:\n",
    "\n",
    "<div style=\"padding: 1ex; margin-top: 1ex; margin-bottom: 1ex; border-style: dotted; border-width: 1pt; border-color: blue; border-radius: 3px;\">\n",
    "B. Regler, M. Scheffler, and L. M. Ghiringhelli: \"TCMI: a non-parametric mutual-dependence estimator for multivariate continuous distributions\" [<a href=\"https://arxiv.org/abs/2001.11212\">arxiv:2001.11212</a>] [<a href=\"https://arxiv.org/pdf/2001.11212\">pdf</a>]\n",
    "</div>\n",
    "\n",
    "TCMI is a measure of the relevance of mutual dependencies based on cumulative probability distributions. TCMI can be estimated directly from sample data and is a non-parametric, robust and deterministic measure that facilitates comparisons and rankings between feature sets with different cardinality. The ranking induced by TCMI allows for feature selection, i.e. the identification of the set of relevant features that are statistical related to the process or the property of a system, while taking into account the number of data samples as well as the cardinality of the feature subsets.\n",
    "\n",
    "It is compared to [Cumulative mutual information (CMI)](https://dx.doi.org/10.1137/1.9781611972832.22), [Multivariate maximal correlation analysis (MAC)](http://proceedings.mlr.press/v32/nguyenc14.html), [Universal dependency analysis (UDS)](https://dx.doi.org/10.1137/1.9781611974348.89), and [Monte Carlo dependency estimation (MCDE)](https://dx.doi.org/10.1145/3335783.3335795).\n",
    "\n",
    "This repository (notebook and code) is released under the [Apache License, Version 2.0](http://www.apache.org/licenses/). Please see the [LICENSE](LICENSE) file.\n",
    "\n",
    "---\n",
    "\n",
    "**Important notes:**\n",
    "<ul style=\"color: #8b0000; font-style: italic;\">\n",
    "<li>All comparisons have been computed with the Java package <code>MCDE v1.0</code> written in Scala, which is not part of the repository due to licensing issues. To download the package, please visit <a href=\"https://github.com/edouardfouche/MCDE-experiments/tree/f90c026d31a90f55e5c2be968cef199f836eae68\">https://github.com/edouardfouche/MCDE-experiments</a>. To build the package, use the <code>sbt</code> build command (sbt compile, sbt package, sbt assembly). Then, copy the resulting java package into the <code>assets</code> folder, rename it to <code>mcde.jar</code>, and run all examples with 50,000 iterations.</li>\n",
    "<li>For the sake of simplicity, all results have been cached. However, results can be recalculated after adjusting the respective test sections. Depending on the test, the calculation time ranges from minutes to days.</li>\n",
    "</ul>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:31.333632Z",
     "start_time": "2022-02-28T16:22:31.326848Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Toggle caching\n",
    "use_cache = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:33.841632Z",
     "start_time": "2022-02-28T16:22:31.339132Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import joblib\n",
    "import warnings\n",
    "import functools\n",
    "import itertools\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import lightgbm as lgbm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Our package\n",
    "import tcmi\n",
    "from tcmi import utils\n",
    "from tcmi import entropy\n",
    "from tcmi.cache import Cache\n",
    "from tcmi.subspace_search import get_subspaces\n",
    "from tcmi.estimators import DependenceEstimator\n",
    "from tcmi.model_selection import RepeatedSortedStratifiedKFold, get_statistics\n",
    "\n",
    "\n",
    "def get_storage_data(key, default=None, overwrite=False, force=False):\n",
    "    \"\"\"Wrapper for storage access. Uses use_cache.\n",
    "    \"\"\"\n",
    "    return storage.get(key, default) if not force and (use_cache or overwrite) else default\n",
    "\n",
    "\n",
    "# Main loop\n",
    "if __name__ == '__main__': \n",
    "    # Provide cache\n",
    "    storage = Cache('data')\n",
    "    \n",
    "    # Configure plot environment\n",
    "    mpl.rc('font', family='sans', size=14)\n",
    "    mpl.rcParams.update({\n",
    "        'figure.facecolor': (0, 0, 0, 0),\n",
    "        'axes.facecolor': (0, 0, 0, 0),\n",
    "        'xtick.labelsize': 14,\n",
    "        'ytick.labelsize': 14\n",
    "    })\n",
    "    \n",
    "    # Define colors\n",
    "    cmap1 = plt.get_cmap('cividis')\n",
    "    cmap2 = plt.get_cmap('RdBu_r')\n",
    "    cmap_neutral = plt.get_cmap('binary')\n",
    "    \n",
    "    neutral_color1 = '#666666'\n",
    "    neutral_color2 = '#999999'\n",
    "    neutral_color3 = '#cccccc'\n",
    "    \n",
    "    # General settings (please do not touch)\n",
    "    kwargs = dict(n_jobs=-1, return_scores=True)\n",
    "    seed = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T17:02:13.549676Z",
     "start_time": "2020-01-13T17:02:13.547302Z"
    }
   },
   "source": [
    "## 1. Basic tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section studies some of the properties of total cumulative mutual information. In particular, we check that the\n",
    "\n",
    "- score is a monotonous function in the order of the conditionals\n",
    "- score attains it's maximum and minimun theoretical values (linear and zero case)\n",
    "- correction vanishes with increasing number of data samples\n",
    "- adjusted version of the score is (almost) constant with respect to subset dimensionality and sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:18.303241Z",
     "start_time": "2022-02-28T16:22:18.297723Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test case 1\n",
    "methods = ['cmi', 'mac', 'uds', 'mcde']\n",
    "size = 200\n",
    "\n",
    "# Test case 2\n",
    "sizes = [10, 50, 100, 500]\n",
    "n_repeats = 50\n",
    "dimensions = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Monotonicity check and ranking of monotonous functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T09:24:46.755127Z",
     "start_time": "2020-01-14T09:24:46.752304Z"
    }
   },
   "source": [
    "**Test**: Monotonicity check of score<br />\n",
    "**Expected**: linear must be first, followed by step functions, zero must be last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:18.643888Z",
     "start_time": "2022-02-28T16:22:18.309998Z"
    }
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=seed)\n",
    "tests = {\n",
    "    # Common operations\n",
    "    'linear': np.arange(size),\n",
    "    'exponential': np.exp(np.linspace(0, 1, num=size)),\n",
    "\n",
    "    # Adding copies of values\n",
    "    'step_2': np.repeat(np.arange(size // 2), 2),\n",
    "    'step_4': np.repeat(np.arange(size // 4), 4),\n",
    "    'step_8': np.repeat(np.arange(size // 8), 8),\n",
    "\n",
    "    # Interleave copies\n",
    "    'sawtooth_2': np.stack(tuple(zip(*[np.arange(2) for i in range(size // 2)])),\n",
    "                     axis=1).flatten(),\n",
    "    'sawtooth_4': np.stack(tuple(zip(*[np.arange(4) for i in range(size // 4)])),\n",
    "                     axis=1).flatten(),\n",
    "    'sawtooth_8': np.stack(tuple(zip(*[np.arange(8) for i in range(size // 8)])),\n",
    "                     axis=1).flatten(),\n",
    "    \n",
    "    'random': rng.random_sample(size),\n",
    "    'zero': np.zeros(size)\n",
    "}\n",
    "\n",
    "ranks = {}\n",
    "output = np.arange(size) + 1\n",
    "\n",
    "for name, value in tests.items():\n",
    "    # Compute scores from other dependency measures for comparison\n",
    "    key = 'monotonicity-check-' + name   \n",
    "    scores = get_storage_data(key, [], overwrite=True)\n",
    "    \n",
    "    if not scores:\n",
    "        score, scores = entropy.cumulative_mutual_information(output, (value, ), **kwargs)\n",
    "        scores = list(s.mean() for s in scores)\n",
    "        \n",
    "        # Compute scores from other dependency measures for comparison\n",
    "        for method in methods:                \n",
    "            estimator = DependenceEstimator(method=method, n_jobs=-1)\n",
    "            score = estimator.score(value, output)\n",
    "            scores.append(score)\n",
    "    \n",
    "    ranks[name] = [np.around(s, decimals=4) for s in scores]\n",
    "    \n",
    "    # Compute correlation\n",
    "    correlation = 0\n",
    "    if np.unique(value).size > 1:\n",
    "        correlation = sp.stats.spearmanr(output, value)[0]\n",
    "    ranks[name].insert(0, np.around(correlation**2, decimals=4))\n",
    "\n",
    "# Show ranking\n",
    "ranks = sorted(ranks.items(), key=lambda x: x[1], reverse=True)\n",
    "index, data = tuple(zip(*ranks))\n",
    "data = np.array([(rho, total, s, np.sum([s01, s02])) + tuple(rest)\n",
    "                 for rho, total, s, s01, s02, *rest in data])\n",
    "\n",
    "columns = ['rho2', 'adjusted_score', 'score', 'score0']\n",
    "columns.extend(methods)\n",
    "\n",
    "ranks = pd.DataFrame(data, index=index, columns=columns)\n",
    "ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Dependence of the correction term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**: Baseline correction dependence with respect to number of data samples<br />\n",
    "**Expected**: Baseline correction monotonically decreases in the number of data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:19.634190Z",
     "start_time": "2022-02-28T16:22:18.650511Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "key = 'correction-term'\n",
    "steps = np.concatenate((np.linspace(1, 9, num=9), np.linspace(10, 100, num=10)))\n",
    "\n",
    "values = get_storage_data(key, [])\n",
    "if len(values) == 0:\n",
    "    values = np.zeros(len(steps), dtype=np.float_)\n",
    "    for i, size in enumerate(steps):\n",
    "        output = np.arange(size) + 1\n",
    "        if size == 1:\n",
    "            values[i] = 1\n",
    "            continue\n",
    "\n",
    "        ce = entropy.cumulative_entropy(output)\n",
    "        hce0 = entropy.cumulative_baseline_correction(output, output, n_jobs=-1)\n",
    "        score0 = 1 - hce0 / ce\n",
    "\n",
    "        # Save average score\n",
    "        values[i] = score0.mean()\n",
    "    \n",
    "##\n",
    "# Plot dependence\n",
    "##    \n",
    "offset = 19\n",
    "fig, ax = plt.subplots(figsize=plt.figaspect(1), dpi=100)\n",
    "\n",
    "# Plot baseline correction\n",
    "ax.plot(steps[:offset], values[:offset], '-o', color=cmap1(0.1),\n",
    "        clip_on=False, linewidth=2, label=r'$\\langle \\hat{\\mathcal{D}}^{(\\prime)}_0(Y; X) \\rangle$')\n",
    "ax.plot(steps[:offset], steps[:offset]**(-2/3), color=cmap2(0.9),\n",
    "        linestyle='--', label='Fit')\n",
    "\n",
    "# Show approximate relationship\n",
    "ax.annotate(r'$\\langle \\hat{\\mathcal{D}}^{(\\prime)}_0(Y; X) \\rangle \\sim n^{-2/3}$',\n",
    "            (20, 0.4), color=cmap2(0.9),fontsize=15)\n",
    "\n",
    "# Plot styles\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.spines['left'].set_position(('outward', 10))\n",
    "ax.spines['bottom'].set_position(('outward', 10))\n",
    "\n",
    "# Set axis limits\n",
    "ax.set_xlim(0, steps[offset - 1])\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "ax.set_xlabel('Sample size $n$')\n",
    "ax.set_ylabel(r'$\\langle \\hat{\\mathcal{D}}_0(Y; X) \\rangle\\ /\\ \\langle \\hat{\\mathcal{D}}_0^\\prime(Y; X) \\rangle$')\n",
    "\n",
    "ax.legend(loc='upper right', facecolor='w', frameon=False, bbox_to_anchor=(1.1, 1.05))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show table\n",
    "pd.DataFrame(np.atleast_2d(values), columns=steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Baseline correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**: Baseline correction of measure with respect to number of samples and dimension<br />\n",
    "**Expected**: Constant scores for different dimensionalities and number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:19.778049Z",
     "start_time": "2022-02-28T16:22:19.639115Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for size in sizes:\n",
    "    output = np.arange(size) + 1\n",
    "    print('\\n:: Size: {:d}\\n'.format(size))\n",
    "    \n",
    "    dtypes = [('dimension', np.int_), ('score', np.float_)]\n",
    "    cache_key = 'baseline_correction.method={:s}_size={:d}_dimension={:d}_repeats={:d}'        \n",
    "    \n",
    "    # Compute scores from other dependency measures for comparison\n",
    "    for method in methods + [\"tcmi\"]:\n",
    "        print(\"/**\\n\"\n",
    "              \" * Method: {:s}\\n\"\n",
    "              \" */\\n\".format(method))\n",
    "        \n",
    "        if method == \"tcmi\":\n",
    "            dtypes = [('total_score', np.float_), ('score', np.float_),\n",
    "                      ('score_corr', np.float_), ('score0', np.float_)]\n",
    "        else:\n",
    "            dtypes = np.float_\n",
    "    \n",
    "        scores_dimensions = np.arange(dimensions + 1, dtype=np.int_)\n",
    "        scores_mean = np.zeros(scores_dimensions.size, dtype=dtypes)\n",
    "        scores_std = np.zeros(scores_dimensions.size, dtype=dtypes)\n",
    "        bucket = results.setdefault(method, {})\n",
    "        \n",
    "        for i, dimension in enumerate(scores_dimensions):\n",
    "            print('- Dimension: {:d} '.format(dimension), end='   ')\n",
    "            \n",
    "            key = cache_key.format(method, size, dimension, n_repeats)\n",
    "            scores = get_storage_data(key, None)\n",
    "            \n",
    "            if scores is None:\n",
    "                # Make sure results are reproducible\n",
    "                rng = np.random.RandomState(seed=seed)\n",
    "                scores = []\n",
    "                \n",
    "                for _ in range(n_repeats):\n",
    "                    if dimension < 1:\n",
    "                        # Add predictions on special first dimensional case\n",
    "                        z = [rng.random_sample(size)]\n",
    "\n",
    "                        noise = 2 * rng.random_sample(size) - 1\n",
    "                        z.append(z[0] + 0.1 * noise)\n",
    "                    else:\n",
    "                        z = [rng.random_sample(size) for _ in range(dimension)]\n",
    "                        \n",
    "                    estimator = DependenceEstimator(method=method, n_jobs=-1)\n",
    "                    score = estimator.score(np.column_stack(z), output)\n",
    "                    scores.append(score)\n",
    "\n",
    "                    # Show update\n",
    "                    print('.', end='')\n",
    "                \n",
    "                # Cache results\n",
    "                scores = np.array(scores)\n",
    "                \n",
    "            # Collect statistics\n",
    "            if method == \"tcmi\":\n",
    "                scores_mean[i] = tuple(np.mean(score) for score in zip(*scores))\n",
    "                scores_std[i] = tuple(np.std(score) for score in zip(*scores))\n",
    "            else:\n",
    "                scores_mean[i] = np.mean(scores)\n",
    "                scores_std[i] = np.std(scores)\n",
    "            print()\n",
    "        \n",
    "        bucket[size] = (scores_dimensions, scores_mean, scores_std)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:26.936061Z",
     "start_time": "2022-02-28T16:22:19.781380Z"
    }
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Plot data\n",
    "##\n",
    "\n",
    "num_rows = len(results[next(iter(results.keys()), None)])\n",
    "ratio = (len(methods) + 1) / (num_rows * (2 / 1.5) + 0.1)\n",
    "\n",
    "width_ratios = np.ones(num_rows, dtype=np.int_)\n",
    "height_ratios = np.full(len(methods) + 1, 1.5, dtype=np.float_)\n",
    "height_ratios[0] = 2\n",
    "\n",
    "##\n",
    "# Figure setup\n",
    "##\n",
    "fig = plt.figure(figsize=(12, 12 / ratio))\n",
    "gs = fig.add_gridspec(len(methods) + 1, num_rows, width_ratios=width_ratios,\n",
    "                      height_ratios=height_ratios, \n",
    "                      wspace=.1, hspace=.3, left=0.1, right=0.98, top=0.98, bottom=0.08)\n",
    "\n",
    "for i, method in enumerate([\"tcmi\"] + methods):\n",
    "    axs = [fig.add_subplot(gs[i, j]) for j in range(num_rows)]\n",
    "    \n",
    "    scores = results[method]\n",
    "    last = method == methods[-1]\n",
    "\n",
    "    x = np.arange(1, dimensions + 1)\n",
    "    y = np.linspace(-1, 1, num=5)\n",
    "    margin = 0.5\n",
    "    \n",
    "    for i, (ax, key) in enumerate(zip(axs, sorted(scores))):\n",
    "        scores_dimension, scores_mean, scores_std = scores[key]\n",
    "        \n",
    "        if method == \"tcmi\":\n",
    "            # Add up all corrections to the score\n",
    "            scores_zero = (scores_mean['total_score'][0], scores_std['total_score'][0])\n",
    "\n",
    "            # Compute mean score from repeated runs\n",
    "            scores_mean = [(adjusted_score, score, np.sum(score0))\n",
    "                           for adjusted_score, score, *score0 in scores_mean[1:]]\n",
    "            adjusted_score, score, score0 = [np.array(values) for values in zip(*scores_mean)]\n",
    "\n",
    "            # Compute standard deviation of score from repeated runs\n",
    "            scores_std = [(adjusted_score, score, np.sum(score0))\n",
    "                          for adjusted_score, score, *score0 in scores_std[1:]]\n",
    "            adjusted_score_std, score_std, score0_std = [np.array(values) for values in zip(*scores_std)]\n",
    "            \n",
    "            # Compute special point (shuffled version)\n",
    "            special_points = [(1, adjusted_score[1])]\n",
    "            \n",
    "            corrected_score = adjusted_score.copy()\n",
    "            corrected_score[0] = scores_zero[0]\n",
    "            constant_line = corrected_score\n",
    "        else:        \n",
    "            scores_zero = (scores_mean[0], scores_std[0])\n",
    "            scores_mean, scores_std = scores_mean[1:], scores_std[1:]\n",
    "            \n",
    "            special_points = [(1, scores_zero[0])]\n",
    "            constant_line = scores_mean\n",
    "        \n",
    "        # Show reference lines\n",
    "        for value in np.linspace(-1, 1, num=9):\n",
    "            ax.axhline(value, color=neutral_color3, linewidth=1, linestyle=':', zorder=-1)\n",
    "        ax.axhline(0, color=neutral_color2, linewidth=1)\n",
    "        \n",
    "        # Plot special point\n",
    "        xx, yy = tuple(zip(*special_points))\n",
    "        ax.errorbar(xx, yy, fmt='x', color=cmap2(0.1), markersize=15, capsize=5, linewidth=5)\n",
    "        \n",
    "        # Show trend line\n",
    "        constant = np.ones_like(constant_line)    \n",
    "        model = np.column_stack((constant, constant))\n",
    "\n",
    "        coeff = np.linalg.lstsq(model, constant_line, rcond=-1)[0]\n",
    "        ax.axhline(np.sum(coeff), color=cmap2(0.1), linewidth=2, linestyle=':',\n",
    "                   label='Average')\n",
    "        \n",
    "        # Plot score contributions\n",
    "        if method == \"tcmi\":\n",
    "            ax.bar(x, score, color=cmap1(0.9), width=0.6, alpha=0.9,\n",
    "                   label=\"Unadjusted score\")\n",
    "            errors = ax.errorbar(x, score, yerr=score_std, color=neutral_color2, clip_on=False,\n",
    "                                 fmt='D', markersize=6, capsize=3, linewidth=1, linestyle=None)\n",
    "            \n",
    "            ax.bar(x, -score0, bottom=0, color=cmap1(0.1), width=0.6, alpha=0.9,\n",
    "                   label=\"Baseline correction\")\n",
    "            ax.errorbar(x, -score0, yerr=score0_std, color=neutral_color2, clip_on=False,\n",
    "                        fmt='D', markersize=6, capsize=3, linewidth=1, linestyle=None)\n",
    "\n",
    "            ax.errorbar(x, adjusted_score, yerr=adjusted_score_std, color=cmap2(0.9),\n",
    "                        fmt='o', label=\"Dependence strength\", #  r'$\\langle \\hat{\\mathcal{D}}_{TCMI}^*(Y; X) \\rangle$', \n",
    "                        markersize=8, capsize=5, linewidth=2)\n",
    "        else:\n",
    "            ax.bar(x, scores_mean, color=cmap1(0.9), width=0.6, clip_on=False,\n",
    "                   label=r'$\\hat{{\\mathcal{{D}}}}_{{{:s}}}(Y; X)$'.format(method), alpha=0.9)\n",
    "            errors = ax.errorbar(x, scores_mean, yerr=scores_std, color=cmap2(0.9), clip_on=False,\n",
    "                                 fmt='o', label=r'$\\hat{{\\mathcal{{D}}}}_{{{:s}}}(Y; X)$'.format(method), \n",
    "                                 markersize=8, capsize=5, linewidth=2)\n",
    "        for b in errors[1]:\n",
    "            b.set_clip_on(False)\n",
    "            \n",
    "        if method == \"tcmi\":\n",
    "            ax.text(x[0] - margin, y[0], 'Sample size: {:d}'.format(key), ha='left',\n",
    "                    va='bottom', fontweight='bold', color=neutral_color1, fontsize='small')\n",
    "        \n",
    "        # Plot styles\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "        ax.spines['left'].set_position(('outward', 10))\n",
    "        ax.spines['bottom'].set_position(('outward', 10))\n",
    "\n",
    "        ax.set_xticks(x)\n",
    "        if last:\n",
    "            ax.set_xticklabels(x)\n",
    "        else:\n",
    "            ax.set_xticklabels([])\n",
    "        ax.set_xlim(x[0] - margin, x[-1] + margin)\n",
    "\n",
    "        # Show axis only for first subfigure\n",
    "        if i > 0:\n",
    "            ax.set_yticklabels([])\n",
    "            ax.spines['left'].set_visible(False)\n",
    "            ax.set_yticks([])\n",
    "        else:\n",
    "            ay = y if method == \"tcmi\" else y[y.size // 2:]\n",
    "            ax.set_yticks(ay)\n",
    "            ax.set_yticklabels(['{:.1f}'.format(v) for v in np.abs(ay)])\n",
    "            \n",
    "            if method == \"tcmi\":\n",
    "                label = ''.join([\n",
    "                    'TCMI\\n',\n",
    "                    r'$\\leftarrow \\langle \\hat{\\mathcal{D}}_0(Y; X) \\rangle$ | '\n",
    "                    r'$\\langle \\hat{\\mathcal{D}}(Y; X) \\rangle \\rightarrow$'\n",
    "                ])\n",
    "            else:\n",
    "                label = \"{name:s}\\n$\\hat{{D}}_{{{name:s}}}(Y; X) \\\\rightarrow$\"\n",
    "                label = label.format(name=method.upper())\n",
    "            ax.set_ylabel(label)\n",
    "        ax.set_ylim(ay[0], ay[-1])\n",
    "        \n",
    "        #aspect = 1.5 if method == \"tcmi\" else 2\n",
    "        #ax.set_aspect(aspect, adjustable=\"datalim\", anchor=\"S\")\n",
    "        \n",
    "        # Show legend\n",
    "        if method == \"tcmi\" and ax is axs[-1]:\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            handles.append(handles.pop(0))\n",
    "            labels.append(labels.pop(0))\n",
    "            cax = fig.add_axes([0.91, 1, .5, 1])\n",
    "\n",
    "            # HACK: Create legend in different context (0.18, -0.825)\n",
    "            legend = plt.legend(handles, labels, loc='lower right', facecolor='w',\n",
    "                                ncol=4, handletextpad=0.4, handlelength=1.5,\n",
    "                                columnspacing=1, bbox_to_anchor=(0.18, -1.006), frameon=False)\n",
    "            cax.remove()\n",
    "            fig.add_artist(legend)\n",
    "            \n",
    "            plt.text(0.2, 0.01, 'Legend:', transform=fig.transFigure)\n",
    "            plt.text(0.08, 0.035, r'Subset dimension $|X| \\longrightarrow$',\n",
    "                     transform=fig.transFigure)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Invariance against scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**: Invariance of TCMI against invertible transformations<br />\n",
    "**Expected**: Same score (here: showcases some very simple examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:27.191982Z",
     "start_time": "2022-02-28T16:22:26.941514Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_groups(data):\n",
    "    # Compare distributions by using cumulative probability \n",
    "    fingerprints = {}\n",
    "    for key, value in data.items():\n",
    "        vs = np.sort(value)\n",
    "        unique_vector = np.searchsorted(vs, value, side='right')\n",
    "        fingerprints[key] = unique_vector.tobytes()\n",
    "\n",
    "    keys = list(data)\n",
    "    duplicates = set()\n",
    "\n",
    "    groups = []\n",
    "    for i, a_key in enumerate(keys, 1):\n",
    "        a_value = fingerprints[a_key]\n",
    "        if a_key in duplicates:\n",
    "            continue\n",
    "\n",
    "        groups.append([a_key])\n",
    "        duplicates.add(a_key)\n",
    "\n",
    "        for b_key in keys[i:]:\n",
    "            if b_key in duplicates:\n",
    "                continue\n",
    "\n",
    "            b_value = fingerprints[b_key]\n",
    "            if a_value == b_value:\n",
    "                groups[-1].append(b_key)\n",
    "                duplicates.add(b_key)\n",
    "    return groups\n",
    "\n",
    "for size in sizes:\n",
    "    print(\":: Size {:d}\".format(size))\n",
    "    \n",
    "    # Reinitialize random number generator for each size\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "\n",
    "    xx = 2 * rng.random_sample(size) - 1\n",
    "    yy = np.linspace(0, 1, num=size)\n",
    "\n",
    "    # Noise term\n",
    "    sigma = 0.1\n",
    "    noise = rng.uniform(low=-1, high=1, size=size)\n",
    "    rr = yy + sigma*noise\n",
    "\n",
    "    # Generate some data and dependences\n",
    "    data = {\n",
    "        'yy': yy,                                         # Target  \n",
    "        'constant': np.ones_like(yy),                     # Constant\n",
    "        'x1': xx, 'x2': np.exp(xx), 'x3': xx**3 + xx,     # Random variables\n",
    "        'r1': rr, 'r2': np.exp(rr), 'r3': rr**3 + rr,     # Target plus noise\n",
    "    }\n",
    "    rands = [rng.randint(-10, 10, 3) for _ in range(5)]\n",
    "    data.update({\n",
    "        \"{:d}x**({:d}){:+d}\".format(a, k, b): a * rr**k + b\n",
    "        for a, k, b in rands\n",
    "    })\n",
    "\n",
    "    # Groups\n",
    "    print(\"\\n/**\\n\"\n",
    "          \" * Groups that must have identical score\\n\"\n",
    "          \" */\\n\")\n",
    "    \n",
    "    groups = get_groups(data)\n",
    "    max_length = max(len(k) for k in data)\n",
    "    for i, group in enumerate(groups, 1):\n",
    "        print(\"  {:d}.  {:s}\".format(i, \" == \".join(g.ljust(max_length) for g in group)))\n",
    "\n",
    "    # Scale invariance\n",
    "    print(\"\\n/**\\n\"\n",
    "          \" * Check scale invariance\\n\"\n",
    "          \" */\\n\")\n",
    "\n",
    "    for method in methods + [\"tcmi\"]:\n",
    "        print(\"{:>4s}:\".format(method), end=\" \")\n",
    "        estimator = DependenceEstimator(method=method, cache=False, n_jobs=-1)\n",
    "        atol = 1e-2 if method == \"mcde\" else 5e-3\n",
    "        \n",
    "        # Last round was not computed with TCMI\n",
    "        if method == \"tcmi\" and size == sizes[-1]:\n",
    "            print(\"n/a\")\n",
    "            continue\n",
    "\n",
    "        failed = False\n",
    "        for group in groups:\n",
    "            results = {}\n",
    "            for feature in sorted(group):\n",
    "                key = \"scale_invariance_{:d}_{:s}_{:s}\".format(size, method, feature)\n",
    "                actual_score = get_storage_data(key, None)\n",
    "                if actual_score is None:\n",
    "                    actual_score = estimator.score(np.column_stack((data[feature], )), yy)\n",
    "\n",
    "                # All variables in a group need to have the same score\n",
    "                prev_score = results.setdefault(\"score\", actual_score)\n",
    "                if not np.isclose(prev_score, actual_score, atol=atol):\n",
    "                    delta = np.abs(prev_score - actual_score)\n",
    "                    failed = True\n",
    "                    \n",
    "                    print(\"\\u2717 (delta={:.1g})\".format(delta))\n",
    "                    break\n",
    "\n",
    "            if failed:\n",
    "                break\n",
    "        else:\n",
    "            print(\"(\\u2713)\" if method == \"mcde\" else \"\\u2713\")\n",
    "\n",
    "    # Permutation invariance\n",
    "    print(\"\\n/**\\n\"\n",
    "          \" * Check permutation invariance\\n\"\n",
    "          \" */\\n\")\n",
    "\n",
    "    for method in methods + [\"tcmi\"]:\n",
    "        print(\"{:>4s}:\".format(method), end=\" \")\n",
    "        estimator = DependenceEstimator(method=method, cache=False, n_jobs=-1)\n",
    "        atol = 1e-2 if method == \"mcde\" else 5e-3\n",
    "        \n",
    "        # Last round was not computed with TCMI\n",
    "        if method == \"tcmi\" and size == sizes[-1]:\n",
    "            print(\"n/a\")\n",
    "            continue\n",
    "\n",
    "        failed = False\n",
    "        for a_keys in groups:\n",
    "            b_keys = sorted(set(data).difference(a_keys))\n",
    "\n",
    "            results = {}\n",
    "            for k1, k2 in itertools.product(sorted(a_keys), b_keys):\n",
    "                key = \"permuation_invariance_{:d}_{:s}_{:s}_{:s}\".format(size, method, k1, k2)\n",
    "                actual_score = get_storage_data(key, None)\n",
    "                if actual_score is None:\n",
    "                    actual_score = estimator.score(np.column_stack((data[k1], data[k2])), yy)\n",
    "\n",
    "                prev_score = results.setdefault(k2, actual_score)\n",
    "                if not np.isclose(prev_score, actual_score, atol=atol):\n",
    "                    delta = np.abs(prev_score - actual_score)\n",
    "                    failed = True\n",
    "                    \n",
    "                    print(\"\\u2717 (delta={:.1g})\".format(delta))\n",
    "                    break\n",
    "\n",
    "            if failed:\n",
    "                break\n",
    "        else:\n",
    "            print(\"(\\u2713)\" if method == \"mcde\" else \"\\u2713\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bivariate Gaussian distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we examine a simple feature selection task with a known distribution and nonlinear dependencies between features and the output variable. Essentially, we consider bivariate Gaussian distributions with different sample sizes, add noisy features, and test dependency estimators to find the optimal subset of features. Since the ground truth is known and the problem is two-dimensional, we expect only two traits to be selected by all dependency estimators.\n",
    "\n",
    "**Settings:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:27.200422Z",
     "start_time": "2022-02-28T16:22:27.194689Z"
    }
   },
   "outputs": [],
   "source": [
    "methods = ['tcmi', 'cmi', 'mac', 'uds', 'mcde']\n",
    "sizes = [50, 100, 200, 500]\n",
    "\n",
    "seed = 2019\n",
    "num_splits = 10\n",
    "num_repeats = 500\n",
    "\n",
    "# Test case\n",
    "noise_levels = 5\n",
    "num_samples = 500\n",
    "confidence = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:27.380521Z",
     "start_time": "2022-02-28T16:22:27.203287Z"
    }
   },
   "outputs": [],
   "source": [
    "target = 'Gaussian'\n",
    "data = pd.read_csv('data/2d_gaussian.csv', low_memory=False)\n",
    "#data = utils.prepare_data(data, target)\n",
    "\n",
    "# Get data\n",
    "x, z = data.drop(labels=target, axis=1), data[target]\n",
    "\n",
    "# Setup noise levels\n",
    "noises = np.linspace(0, 1, num=noise_levels + 1)\n",
    "\n",
    "# Generate indices for sub-sampling\n",
    "rng = np.random.RandomState(seed=seed)\n",
    "indices = np.arange(data.shape[0])\n",
    "rng.shuffle(indices)\n",
    "\n",
    "# Plot empirical mean and covariance\n",
    "xy = np.vstack((data['x'], data['y']))\n",
    "pretty_print = lambda x: re.sub('\\s+', ' ', repr(x))\n",
    "print('Empirical mean       = {}\\nEmpirical covariance = {}'\n",
    "      .format(pretty_print(np.mean(xy, axis=-1)), pretty_print(np.cov(xy))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Check score of optimal feature subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**: List TCMI scores for optimal two-dimensional subset `{x,y}`<br />\n",
    "**Expected**: TCMI scores of `{x,y}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:27.550958Z",
     "start_time": "2022-02-28T16:22:27.384282Z"
    }
   },
   "outputs": [],
   "source": [
    "estimator = DependenceEstimator(method='tcmi', n_jobs=-1)\n",
    "key = 'gaussian_optimal_subspace'\n",
    "\n",
    "gaussian = data.iloc[indices[:sizes[-1]]]\n",
    "\n",
    "scores = get_storage_data(key, None)\n",
    "if scores is None:\n",
    "    scores = []\n",
    "    for k1, k2 in itertools.product(['x', '-x', '|x|', '-|x|'], ['y', '-y', '|y|', '-|y|']):\n",
    "        temp_xy, temp_z = gaussian[[k1, k2]], gaussian[target]\n",
    "        score = estimator.score(temp_xy, temp_z)\n",
    "        scores.append((k1, k2, score))\n",
    "        \n",
    "    scores.sort(key=lambda x: -x[-1])\n",
    "\n",
    "print('\\n'.join('{{{:s},{:s}}} = {:.3f}'.format(*s) for s in scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Compute subset score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**: Compute subset score `{x, y}` -> z with respect to increasing number of data points<br />\n",
    "**Expected**: Monotonic increase for information-theoretic measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:27.748377Z",
     "start_time": "2022-02-28T16:22:27.559698Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for size in sizes:\n",
    "    gaussian = np.take(xy, indices[:size], axis=-1)\n",
    "    output = np.take(z, indices[:size], axis=0)\n",
    "    gaussian = gaussian.T\n",
    "    \n",
    "    results[size] = {}\n",
    "    for method in methods:\n",
    "        estimator = DependenceEstimator(method=method, n_jobs=-1)\n",
    "        key = 'gaussian_xy_{:s}_{:d}'.format(method, size)\n",
    "        \n",
    "        score = get_storage_data(key, default=None, overwrite=bool(method != 'tcmi'))\n",
    "        if score is None:\n",
    "            score = estimator.score(gaussian, output)\n",
    "            storage.set(key, score)\n",
    "        results[size].setdefault(method, score)\n",
    "    \n",
    "df = np.array([[results[size][method] for method in methods] for size in sizes])\n",
    "pd.DataFrame(df, index=sizes, columns=methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Find optimal subset of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**: Find optimal subset of features<br />\n",
    "**Expected**: Optimal subset must be `{x, y}`, prefactors allowed, feature \"normal\" is similar to \"x\" or \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:27.983560Z",
     "start_time": "2022-02-28T16:22:27.751750Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for size in sizes:\n",
    "    gaussian = data.iloc[indices[:size]]\n",
    "    \n",
    "    print('\\n/**'\n",
    "          '\\n * Data points = {:d}'\n",
    "          '\\n */'.format(size))\n",
    "    \n",
    "    results[size] = {}\n",
    "    for method in methods:\n",
    "        estimator = DependenceEstimator(method=method, n_jobs=-1)\n",
    "        key = 'gaussian_subspace_{:s}_{:d}'.format(method, size)\n",
    "        \n",
    "        subsets = get_storage_data(key, default=None, overwrite=bool(method != 'tcmi'))\n",
    "        if subsets is None:\n",
    "            subsets = tcmi.get_subspaces(gaussian, target, estimator, cv=None,\n",
    "                                         depth=2, scoring='mutual_information_score',\n",
    "                                         fit_params=None, verbose=1, n_jobs=-1)\n",
    "            \n",
    "        subsets = utils.filter_subsets(subsets, remove_duplicates=True)\n",
    "        \n",
    "        output = []\n",
    "        cursor = 3\n",
    "        cursor = -1\n",
    "        threshold = 1\n",
    "        \n",
    "        has_xy = False\n",
    "        for i, subset in enumerate(subsets):\n",
    "            subspace = subset['subspace']\n",
    "            score = subset['stats']['mutual_information_score_mean']\n",
    "            depth = len(subspace)\n",
    "            \n",
    "            if i == 0 or cursor == -1 or cursor > depth:\n",
    "                line = '[{:>3d}] {{{:s}}} = {:.2f}'.format(\n",
    "                    len(subspace), ','.join(subspace), score)\n",
    "                output.append(line)\n",
    "                \n",
    "                if i > 0 or cursor == -1:\n",
    "                    threshold = 0.95 * score\n",
    "                    cursor = depth\n",
    "            \n",
    "            elif score > threshold:\n",
    "                line = '[{:>3d}] {{{:s}}} = {:.2f}'.format(\n",
    "                    len(subspace), ','.join(subspace), score)\n",
    "                output.append(line)\n",
    "        \n",
    "        results[size].setdefault(method, subsets)\n",
    "        print('\\nMethod: {:s}\\n  {:s}'.format(method, '\\n  '.join(output)))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Statistical power analysis (95% confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform statistical power analysis we see, that all of the above dependency measures converge to the optimal feature subsets ${x,y}$ for at least 500 data samples, which will be chosen as the sample size in the following.\n",
    "\n",
    "**Test**: Statistical power analysis (95% confidence)<br />\n",
    "**Expected**: High statistical power as well as high contrast between the actual score and independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:28.320468Z",
     "start_time": "2022-02-28T16:22:27.987580Z"
    },
    "code_folding": [
     0,
     34
    ]
   },
   "outputs": [],
   "source": [
    "def generate_dataset(data, target, noise, n_splits=10, n_repeats=100, seed=None):\n",
    "    \"\"\"Generate data set.\n",
    "    \"\"\"\n",
    "    size = data.shape[0]\n",
    "\n",
    "    # Convert cross-validation into number of data samples\n",
    "    cv = np.floor(size * (n_splits if n_splits < 1 else (1 - 1 / n_splits))).astype(np.int_)\n",
    "\n",
    "    # Initialize generator\n",
    "    rng = np.random.RandomState(seed)\n",
    "    indices = np.arange(size)\n",
    "\n",
    "    # Evaluate dataset\n",
    "    noise /= 2\n",
    "    for _ in range(n_repeats):\n",
    "        # Split dataset and make sure to make vectors immutable\n",
    "        index = indices[:cv].copy()\n",
    "        dataset = data.iloc[index].copy()\n",
    "        \n",
    "        # Add (centered) noise\n",
    "        for key in dataset:\n",
    "            if key == target:\n",
    "                continue\n",
    "            \n",
    "            # Center noise around actual value\n",
    "            dataset[key] += rng.uniform(-noise, noise, size=cv)\n",
    "\n",
    "        # Return generated dataset\n",
    "        yield dataset, index\n",
    "\n",
    "        # Prepare for next iteration\n",
    "        rng.shuffle(indices)\n",
    "        \n",
    "        \n",
    "def compute_score(method, noise, dataset, indices):\n",
    "    \"\"\"Compute score for dataset.\n",
    "    \"\"\"\n",
    "    # Setup\n",
    "    test_xy, test_z = dataset.drop(labels=target, axis=1), dataset[target]\n",
    "    estimator = DependenceEstimator(method=method, n_jobs=1, cache=None)\n",
    "    h = cache.compute_hash((dataset, indices))\n",
    "\n",
    "    # Compute measure with respect to output\n",
    "    key = 'score_{:s}_{:.2f}_{:s}'.format(method, noise, h)\n",
    "    score = storage.get(key, None)\n",
    "    if score is None:\n",
    "        score = estimator.score(test_xy, test_z)\n",
    "        storage.set(key, score, retry=True)\n",
    "\n",
    "    # Compute measure with respect to independent variables\n",
    "    key = 'score0_{:s}_{:.2f}_{:s}'.format(method, noise, h)\n",
    "    score0 = storage.get(key, None)\n",
    "    if score0 is None:\n",
    "        score0 = estimator.score(test_independent[indices], test_z)\n",
    "        storage.set(key, score0, retry=True)\n",
    "\n",
    "    # Return scores\n",
    "    return score, score0\n",
    "\n",
    "\n",
    "datasets = [\n",
    "    ('Bivariate normal distribution: $\\{x,y\\}$', 'gaussian', 'data/2d_gaussian.csv', \n",
    "     'Gaussian', ('-|x|', '-|y|'))\n",
    "]\n",
    "\n",
    "collections = []\n",
    "for label, name, file, target, subset in datasets:\n",
    "    data = pd.read_csv(file, low_memory=False)\n",
    "    if target == 'Delta E':\n",
    "        del data['Combination']\n",
    "        \n",
    "    print('\\n/**'\n",
    "          '\\n * Data set: {:s}'\n",
    "          '\\n */\\n'.format(name))\n",
    "        \n",
    "    data = utils.prepare_data(data, target)\n",
    "    size = min(len(data), num_samples)\n",
    "    subset += (target, )\n",
    "\n",
    "    # Setup noise levels\n",
    "    noises = np.linspace(0, 1, num=noise_levels + 1)\n",
    "\n",
    "    # Generate indices for test set\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    indices = np.arange(len(data))\n",
    "    rng.shuffle(indices)\n",
    "\n",
    "    # Consider subset of data samples\n",
    "    data = data[list(subset)].iloc[indices[:size]]\n",
    "    test_independent = rng.uniform(0, 1, (size, 2))\n",
    "\n",
    "    dtypes = [('noise', np.float_), ('power', np.float_),\n",
    "              ('score', np.float_), ('score0', np.float_)]\n",
    "    print('Data points = {:d}\\nNoise levels = {:d}'\n",
    "          .format(size, len(noises)))\n",
    "\n",
    "    # Initialize joblib\n",
    "    processor = joblib.Parallel(n_jobs=-1)\n",
    "    callback = joblib.delayed(compute_score)\n",
    "    \n",
    "    # Compute statistical power\n",
    "    collection = {}\n",
    "    for method in methods:\n",
    "        print('\\nMethod: {:s}\\n  '.format(method), end='')\n",
    "\n",
    "        statistics = np.zeros(noises.size, dtype=dtypes)\n",
    "        for i, noise in enumerate(noises):\n",
    "            print('{:.2f}'.format(noise), end=', ')\n",
    "\n",
    "            key = '{:s}_statistical_power_{:s}_{:d}_noise_{:.2f}'\n",
    "            key = key.format(name, method, size, noise)\n",
    "            values = get_storage_data(key, default=None, overwrite=bool(method != 'tcmi'))\n",
    "\n",
    "            if values is None:\n",
    "                # Perform calculation in parallel\n",
    "                iterator = generate_dataset(data, target, noise, n_splits=num_splits,\n",
    "                                            n_repeats=num_repeats, seed=seed)\n",
    "                values = processor(callback(name, method, noise, dataset, indices)\n",
    "                                   for dataset, indices in iterator)\n",
    "                scores, scores0 = tuple(zip(*values))\n",
    "\n",
    "                values = tuple(np.array(value) for value in zip(*values))\n",
    "\n",
    "            # Compute statistical power\n",
    "            scores, scores0 = values\n",
    "            cutoff = np.quantile(scores0, confidence)\n",
    "\n",
    "            power = np.mean(scores > cutoff)\n",
    "            score_avg = scores.mean()\n",
    "            score0_avg = scores0.mean()\n",
    "\n",
    "            # Save statistical power statistics\n",
    "            statistics[i] = (noise, power, score_avg, score0_avg)\n",
    "\n",
    "        print('\\n')\n",
    "        for values in statistics:\n",
    "            print('Noise = {:.2f}, Power = {:.2f}, Score = {:.2f}, Score0 = {:.2f}'.format(*values))     \n",
    "        collection[method] = statistics\n",
    "    \n",
    "    collections.append((label, collection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:29.486159Z",
     "start_time": "2022-02-28T16:22:28.328341Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Plot\n",
    "##\n",
    "\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "# Plot\n",
    "margin = 0.1\n",
    "ncols = len(methods)\n",
    "nrows = len(collections)\n",
    "idx = np.where(np.arange(noise_levels + 1) % 2 == 0)[0]\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(16, 3 * nrows), ncols=ncols, nrows=nrows) \n",
    "if len(collections) == 1:\n",
    "    axs = [axs]\n",
    "\n",
    "handlers = []\n",
    "for i, (caxs, item) in enumerate(zip(axs, collections)):\n",
    "    name, collection = item\n",
    "    \n",
    "    for j, (ax, method) in enumerate(zip(caxs, methods)):\n",
    "        # Show reference lines\n",
    "        for y in np.linspace(0, 1, num=5):\n",
    "            ax.axhline(y, color=neutral_color3, linewidth=1, linestyle=':', zorder=-1)\n",
    "\n",
    "        # Get data\n",
    "        data = collection[method]\n",
    "\n",
    "        # Initialize coordinates\n",
    "        x = data['noise']\n",
    "        y = np.linspace(0, 1, num=5)\n",
    "        color = 0.8 * (j / len(methods)) + 0.1\n",
    "\n",
    "        # Show contrast of score\n",
    "        score = np.maximum(data['score'] - data['score0'], 1e-2)\n",
    "        bars = ax.bar(x, data['score'], data['score0'])\n",
    "        handler = ax.fill_between(x, data['score'], data['score0'], color=cmap1(color),\n",
    "                                  label='Dependence scores')\n",
    "        handlers.append(handler)\n",
    "        \n",
    "        if j == 0:\n",
    "            ax.text(x.min() - 0.1, y.max() + 0.17, name, va='bottom', ha='left')\n",
    "\n",
    "        ax.plot(x, data['power'], color=cmap2(0.9), marker='s', clip_on=False,\n",
    "                label='Statistical power ($\\gamma = 0.95$)')\n",
    "\n",
    "        ax.text(x[0] - margin, y[-1] + 0.05, method.upper(), ha='left',\n",
    "                va='bottom', fontweight='bold', color=neutral_color1, fontsize='small')\n",
    "\n",
    "        # Show statistical power\n",
    "        for bar, value, value0, score0 in zip(bars, data['power'], score, data['score0']):\n",
    "            bar_x = bar.get_x() + bar.get_width() / 2 # - 0.01 * bar.get_width()\n",
    "            bar_y = bar.get_y() + bar.get_height() + 0.05\n",
    "            text = '{:.2f}'.format(value)\n",
    "\n",
    "            va = 'bottom'\n",
    "            if value > 0.5:\n",
    "                value -= 0.04\n",
    "                va = 'top'\n",
    "\n",
    "            if value < 0.5: # or value > 0.9:\n",
    "                value += 0.08\n",
    "                va = 'bottom'\n",
    "                \n",
    "            text = ax.text(bar_x, value - 0.02, text, ha='center', va=va,\n",
    "                           fontsize='small', color=cmap2(0.9), rotation=90)\n",
    "            text.set_path_effects(\n",
    "                [path_effects.withStroke(linewidth=5, foreground='w')])\n",
    "\n",
    "        bars.remove()\n",
    "\n",
    "        # Plot styles\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "        ax.spines['left'].set_position(('outward', 10))\n",
    "        ax.spines['bottom'].set_position(('outward', 10))\n",
    "\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xlim(x[0] - margin, x[-1] + margin)\n",
    "        #ax.set_xlabel('Noise levels')\n",
    "\n",
    "        # Show axis only for first subfigure\n",
    "        if j > 0:\n",
    "            ax.set_yticklabels([])\n",
    "            ax.spines['left'].set_visible(False)\n",
    "            ax.set_yticks([])\n",
    "        else:\n",
    "            ax.set_yticks(y)\n",
    "            ax.set_yticklabels(['{:.2f}'.format(value) for value in y])\n",
    "            ax.set_ylabel('Score/Power')\n",
    "        ax.set_ylim(y[0], y[-1])\n",
    "        ax.set_xlim(x[0], x[-1])\n",
    "    \n",
    "    # Show legend\n",
    "    if caxs is axs[-1]:\n",
    "        handles, labels = ax.get_legend_handles_labels() \n",
    "        handles[-1] = tuple(handlers)\n",
    "        \n",
    "        cax = fig.add_axes([1, 1, 0, 1])\n",
    "        \n",
    "        # HACK: Create legend in different context\n",
    "        # https://matplotlib.org/3.1.1/gallery/text_labels_and_annotations/legend_demo.html\n",
    "        legend = plt.legend(handles[::-1], labels[::-1], loc='upper right', facecolor='w',\n",
    "                            ncol=3, handletextpad=0.3, handlelength=2, numpoints=1,\n",
    "                            columnspacing=0.75, bbox_to_anchor=(0, -1), frameon=False,\n",
    "                            handler_map={tuple: HandlerTuple(ndivide=None,pad=0)})\n",
    "        \n",
    "        # Get the bounding box of the original legend\n",
    "        bb = legend.get_bbox_to_anchor().inverse_transformed(ax.transAxes)\n",
    "\n",
    "        # Change to location of the legend. \n",
    "        xOffset = -0.6\n",
    "        bb.x0 += xOffset\n",
    "        bb.x1 += xOffset\n",
    "        legend.set_bbox_to_anchor(bb, transform = ax.transAxes)\n",
    "\n",
    "        cax.remove()\n",
    "        fig.add_artist(legend)\n",
    "        \n",
    "        ax.text(0.48, -0.12, 'Legend:', transform=fig.transFigure)\n",
    "        ax.text(0.07, -0.12, r'Noise levels $\\longrightarrow$', transform=fig.transFigure)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. UCI Regression data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Friedman - https://sci2s.ugr.es/keel/dataset.php?cod=81 . It has been obtained from the LIACC repository. The original page where the data set can be found is: http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html.\n",
    "2. Concrete Compressive Strength - https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength\n",
    "3. Forest Fires Data Set - https://archive.ics.uci.edu/ml/datasets/Forest+Fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:29.492308Z",
     "start_time": "2022-02-28T16:22:29.488431Z"
    }
   },
   "outputs": [],
   "source": [
    "methods = ['tcmi', 'cmi', 'mac', 'uds', 'mcde']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Generate Friedman data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:29.726279Z",
     "start_time": "2022-02-28T16:22:29.496462Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://blog.datadive.net/selecting-good-features-part-iv-stability-selection-rfe-and-everything-side-by-side/\n",
    "# Friedman #1 regression dataset \n",
    "\n",
    "np.random.seed(0)\n",
    " \n",
    "size = 500\n",
    "target = 'y'\n",
    "\n",
    "# \"Friedamn #1 regression problem\n",
    "X = np.random.uniform(0, 1, (size, 14))\n",
    "Y = (10 * np.sin(np.pi*X[:,0]*X[:,1]) + 20*(X[:,2] - .5)**2 +\n",
    "     10*X[:,3] + 5*X[:,4] + np.random.normal(0,1))\n",
    "#Add 3 additional correlated variables (correlated with X1-X3)\n",
    "X[:,10:] = X[:,:4] + np.random.normal(0, .025, (size,4))\n",
    " \n",
    "names = [\"x%s\" % (i + 1) for i in range(X.shape[-1])]\n",
    "data = pd.DataFrame(data=X, columns=names)\n",
    "data[target] = Y\n",
    "\n",
    "# data.to_csv('data/friedman.csv', index=False)\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Show which features have strong correlations\n",
    "for key in data:\n",
    "    if key == target:\n",
    "        continue\n",
    "    \n",
    "    r2 = np.corrcoef(data[key], data[target])[0, 1]**2\n",
    "    rho, pval = stats.spearmanr(data[key], data[target])\n",
    "    print('{:<3s}: r2={:<4.2f}  rho={:>5.2f}  pval={:<.2g}'\n",
    "          .format(key, r2, rho, pval))\n",
    "    \n",
    "x, z = data.drop(labels=target, axis=1), data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Optimal subspace search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**: Find optimal subsets for several available datasets<br />\n",
    "**Expected**: Convergence and stability of all dependence measures to the same subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:30.273036Z",
     "start_time": "2022-02-28T16:22:29.728668Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "datasets = [\n",
    "    ('friedman', 'data/friedman.csv', 'y'),\n",
    "    ('concrete', 'data/concrete.csv', 'compressive_strength'),\n",
    "    ('forest_fires', 'data/forestfires.csv', 'area')\n",
    "]\n",
    "\n",
    "for name, filename, target in datasets:\n",
    "    data = pd.read_csv(filename, low_memory=False)\n",
    "    data = utils.prepare_data(data, target)\n",
    "    \n",
    "    print('\\n/**'\n",
    "          '\\n * Model: {:s}'\n",
    "          '\\n */\\n'\n",
    "          '\\nKeys: {{{:s}}}'\n",
    "          '\\nSize: {:d}'\n",
    "          .format(name, ','.join(data), data.shape[-1] - 1))\n",
    "    \n",
    "    for method in methods:\n",
    "        estimator = DependenceEstimator(method=method, n_jobs=1)\n",
    "        key = 'subspace_search_{:s}_{:s}'.format(target, method)\n",
    "        print('\\nMethod: {:s}'.format(method))\n",
    "\n",
    "        subsets = get_storage_data(key, default=None, overwrite=bool(method != 'tcmi'))\n",
    "        if subsets is None:\n",
    "            subsets = tcmi.get_subspaces(data, target, estimator, cv=None,\n",
    "                                         depth=-1, scoring='mutual_information_score',\n",
    "                                         fit_params=None, verbose=1, n_jobs=-1)\n",
    "\n",
    "        output = []\n",
    "        if len(subsets) > 1000:\n",
    "            output.append('More than {:d} subsets.'.format(len(subsets)))\n",
    "        else:            \n",
    "            cursor = -1\n",
    "            threshold = 1\n",
    "            for i, subset in enumerate(subsets):\n",
    "                subspace = subset['subspace']\n",
    "                score = subset['stats']['mutual_information_score_mean']\n",
    "                depth = len(subspace)\n",
    "\n",
    "                if i == 0 or cursor == -1 or cursor > depth:\n",
    "                    line = '[{:>3d}] {{{:s}}} = {:.2f}'.format(\n",
    "                        len(subspace), ','.join(subspace), score)\n",
    "                    output.append(line)\n",
    "\n",
    "                    if i > 0 or cursor == -1:\n",
    "                        threshold = 0.95 * score\n",
    "                        cursor = depth\n",
    "\n",
    "                elif score > threshold:\n",
    "                    line = '[{:>3d}] {{{:s}}} = {:.2f}'.format(\n",
    "                        len(subspace), ','.join(subspace), score)\n",
    "                    output.append(line)\n",
    "        print('  {:s}'.format('\\n  '.join(output)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Octet-binary compound semiconductors data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Octet-binary compound semiconductors are materials consisting of two elements formed by groups of I/VII, II/VI, III/V, or IV/IV elements leading to a full valence shell. They crystallize in rock salt (RS) or zinc blende (ZB) structures.\n",
    "\n",
    "The data set is composed of 82 materials with two atomic species in the unit cell. The objective is to accurately predict the energy difference $\\Delta E$ between RS and ZB structures based on 8 electro-chemical atomic properties for each atomic species $A/B$ (in total 16) such as atomic ionization potential $\\text{IP}$, electron affinity $\\text{EA}$, the energies of the highest-occupied and lowest-unoccupied Kohn-Sham levels, $\\text{H}$ and $\\text{L}$, and the expectation value of the radial probability densities of the valence $s$-, $p$-, and $d$-orbitals, $r_s$, $r_p$, and $r_d$, respectively.\n",
    "\n",
    "<div style=\"padding: 1ex; margin-top: 1ex; margin-bottom: 1ex; border-style: dotted; border-width: 1pt; border-color: blue; border-radius: 3px;\">\n",
    "    L. M. Ghiringhelli, J. Vybiral, S. V. Levchenko, C. Draxl, C. & M. Scheffler: Big Data of Materials Science: Critical Role of the Descriptor. Physical Review Letters <strong>114</strong>, 105503 (2015). DOI: <a href=\"https://dx.doi.org/10.1103/PhysRevLett.114.105503\">10.1103/PhysRevLett.114.105503</a>\n",
    "</div>\n",
    "\n",
    "The additional features from the reference are:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    D1 = \\frac{\\text{IP}(B) - \\text{EA}(B)}{r_p(A)^2}\\ ,\\quad \\ D2 = \\frac{|r_s(A) - r_p(B)|}{\\exp[r_s(A)]} \\ .\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Subspace search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T11:32:15.336979Z",
     "start_time": "2020-01-14T11:32:15.333046Z"
    }
   },
   "source": [
    "**Test**: Optimal feature subset search<br />\n",
    "**Expected**: Find features to best predict $\\Delta E$. Potential candidates are listed in the reference above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:30.280518Z",
     "start_time": "2022-02-28T16:22:30.276748Z"
    }
   },
   "outputs": [],
   "source": [
    "include_extra_features = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:30.594514Z",
     "start_time": "2022-02-28T16:22:30.284313Z"
    }
   },
   "outputs": [],
   "source": [
    "methods = ['tcmi', 'cmi', 'mac', 'uds', 'mcde']\n",
    "data = pd.read_csv('data/octet-binary-compound-semiconductors.csv', low_memory=False)\n",
    "materials = data.drop(columns='Combination', inplace=True)\n",
    "target = 'Delta E'\n",
    "\n",
    "# Add extra features from PRL?\n",
    "if include_extra_features:\n",
    "    extra = {\n",
    "        'D1': (data['EA(B)'] - data['IP(B)']) / data['rp(A)']**2,\n",
    "        'D2': np.abs(data['rs(A)'] - data['rp(B)']) / np.exp(data['rs(A)'])\n",
    "    }\n",
    "    \n",
    "    for k, v in extra.items():\n",
    "        data[k] = v\n",
    "\n",
    "data = utils.prepare_data(data, target, copy=True)\n",
    "\n",
    "print('\\n/**'\n",
    "      '\\n * Model: Octet-binary compound semiconductors data set'\n",
    "      '\\n */\\n'\n",
    "      '\\nKeys: {{{:s}}}'\n",
    "      '\\nSize: {:d}'\n",
    "      .format(','.join(data), data.shape[-1] - 1))\n",
    "\n",
    "results = {}\n",
    "for method in [\"mcde\", \"uds\"] + methods:\n",
    "    print('\\nMethod: {:s}'.format(method))\n",
    "    estimator = DependenceEstimator(method=method, cache=True)\n",
    "    \n",
    "    key = 'binary_octets_{:s}'.format(method)\n",
    "    subsets = get_storage_data(key, None, force=include_extra_features)\n",
    "    if subsets is None:\n",
    "        subsets = get_subspaces(data, target, estimator, cv=None, depth=-1,\n",
    "                                scoring='mutual_information_score',\n",
    "                                fit_params=None, verbose=1, n_jobs=-1)\n",
    "        storage.set(key, subsets)\n",
    "    \n",
    "    threshold = 1\n",
    "    output = []\n",
    "    cursor = -1\n",
    "    subsets = utils.filter_subsets(subsets)\n",
    "\n",
    "    candidates = []\n",
    "    for i, subset in enumerate(subsets):\n",
    "        subspace = subset['subspace']\n",
    "        score = subset['stats']['mutual_information_score_mean']\n",
    "        depth = len(subspace)\n",
    "\n",
    "        if i == 0 or cursor == -1 or cursor > depth:\n",
    "            line = '[{:>3d}] {{{:s}}} = {:.2f}'.format(\n",
    "                len(subspace), ','.join(subspace), score)\n",
    "            candidates.append((subspace, score))\n",
    "            output.append(line)\n",
    "\n",
    "            if i > 0 or cursor == -1:\n",
    "                threshold = 0.95 * score\n",
    "                cursor = depth\n",
    "\n",
    "        elif score > threshold:\n",
    "            line = '[{:>3d}] {{{:s}}} = {:.2f}'.format(\n",
    "                len(subspace), ','.join(subspace), score)\n",
    "            candidates.append((subspace, score))\n",
    "            output.append(line)\n",
    "\n",
    "    print('  {:s}'.format('\\n  '.join(output)))\n",
    "    keys = sorted([k for k in data.columns if k != target and '|' not in k and '-' not in k],\n",
    "                  key=lambda x: (x[-2], x))\n",
    "    candidates.insert(0, (keys, 1))\n",
    "    results[method] = candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:30.811858Z",
     "start_time": "2022-02-28T16:22:30.599242Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Helper function to get optimal number of estimators\n",
    "def get_estimators(**params):\n",
    "    manager = multiprocessing.Manager()\n",
    "    iterations = manager.list()\n",
    "    lock = manager.Lock()\n",
    "    model = [None, 0]\n",
    "\n",
    "    def stop_model(env):\n",
    "        # Make sure to ignore this model\n",
    "        scores = []\n",
    "        for evaluation in env.evaluation_result_list:\n",
    "            evaluation = list(evaluation)\n",
    "            evaluation[2] = (float('-inf') if evaluation[3] else float('inf'))\n",
    "            scores.append(tuple(evaluation))\n",
    "\n",
    "        # Stop early\n",
    "        raise lgbm.callback.EarlyStopException(env.iteration, scores)\n",
    "    \n",
    "    def _start_callback(env):\n",
    "        if model[0] is not env.model:\n",
    "            model[0] = env.model\n",
    "                \n",
    "            # Process model\n",
    "            with lock: \n",
    "                model[1] = len(iterations)\n",
    "                iterations.append(0)\n",
    "        \n",
    "    def _end_callback(env=None, **kwargs):\n",
    "        result = None\n",
    "        if env:\n",
    "            index = model[1]\n",
    "            iterations[index] = env.iteration\n",
    "            \n",
    "            # Check for valid parameters\n",
    "            settings = env.model.params\n",
    "            if settings['max_depth'] > -1 and settings['num_leaves'] > 2**settings['max_depth']:\n",
    "                stop_model(env)\n",
    "            \n",
    "            for _, name, score, _ in env.evaluation_result_list:\n",
    "                if name in ['l1', 'l2'] and score < params.get('threshold', 0):\n",
    "                    iterations[index] =np.nan\n",
    "                    stop_model(env)\n",
    "        else:\n",
    "            # Adjust number of estimators\n",
    "            result = np.nanmax(iterations)\n",
    "            divisor = kwargs.get('divisor', 0)\n",
    "            if divisor:\n",
    "                result = (result // divisor + 1) * divisor\n",
    "                \n",
    "        return result\n",
    "    \n",
    "    # Internal attributes used inside LightGBM\n",
    "    _start_callback.before_iteration = True\n",
    "    _start_callback.order = 0\n",
    "    _end_callback.order = 1000\n",
    "    return _start_callback, _end_callback\n",
    "\n",
    "\n",
    "num_splits = 10\n",
    "num_repeats = 5\n",
    "\n",
    "# Setup estimator\n",
    "params = {}\n",
    "params['n_estimators'] = 2000\n",
    "params['min_child_samples'] = int(0.01 * data.shape[0])\n",
    "\n",
    "estimator = lgbm.LGBMRegressor(n_jobs=-1, random_state=seed, **params)\n",
    "cv = RepeatedSortedStratifiedKFold(n_splits=num_splits, n_repeats=num_repeats,\n",
    "                                   random_state=seed, side='uniform', test_size=0.1)\n",
    "\n",
    "# Fit params \n",
    "fit_params = dict(eval_metric=['l1', 'l2_root'], early_stopping_rounds=50, verbose=None)\n",
    "x, y = data.drop(labels=target, axis=1), data[target]\n",
    "\n",
    "# Prepare dataset\n",
    "if cv:\n",
    "    preprocess, postprocess = get_estimators(threshold=1e-3)\n",
    "    params = fit_params.copy()\n",
    "    params.update({\n",
    "        'eval_set': [(x.iloc[index], y .iloc[index]) for _, index in cv.split(x, y)],\n",
    "        'callbacks': [preprocess, postprocess]\n",
    "    })\n",
    "else:\n",
    "    params = {}\n",
    "\n",
    "scores_mapping = {\n",
    "    'root_mean_squared_error_mean': 'rmse',\n",
    "    'mean_absolute_error_mean': 'mae',\n",
    "    'max_absolute_error_mean': 'maxae',\n",
    "    'r2_mean': 'r2',\n",
    "    'root_mean_squared_error_std': 'rmse_std',\n",
    "    'mean_absolute_error_std': 'mae_std',\n",
    "    'max_absolute_error_std': 'maxae_std',\n",
    "    'r2_std': 'r2_std'\n",
    "}\n",
    "\n",
    "scorings = ['rmse', 'mae', 'maxae', 'r2']\n",
    "line = '[{size:>3d}] {{{subspace:s}}} = {score:.2f}\\n      '\n",
    "line += '  '.join(scoring + '={' + scoring + ':.3f} +- {' + scoring + '_std:.3f}' for scoring in scorings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T16:22:31.321763Z",
     "start_time": "2022-02-28T16:22:30.816367Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for method in sorted(results):\n",
    "    print(\"/**\\n\"\n",
    "          \" * Method: {:s}\\n\"\n",
    "          \" */\\n\".format(method))\n",
    "    \n",
    "    print(\":: Found {:d} subsets\\n\".format(len(results[method]) - 1))\n",
    "\n",
    "    candidates = results[method]\n",
    "    for index, (candidate, score) in enumerate(candidates):\n",
    "        features = list(candidate)\n",
    "        key = \"subset_{:s}\".format('_'.join(features))\n",
    "        \n",
    "        stats = get_storage_data(key, default=None)\n",
    "        if stats is None:\n",
    "            # Prepare dataset\n",
    "            preprocess, postprocess = get_estimators(threshold=1e-3)\n",
    "            params = fit_params.copy()\n",
    "            xx = x[features]\n",
    "\n",
    "            params.update({\n",
    "                'eval_set': [(xx.iloc[index], y.iloc[index]) for _, index in cv.split(x, y)],\n",
    "                'callbacks': [preprocess, postprocess]\n",
    "            })\n",
    "\n",
    "            stats = get_statistics(estimator, xx, y, cv=cv, fit_params=params,\n",
    "                                   verbose=0, n_jobs=-1)\n",
    "            for old, new in scores_mapping.items():\n",
    "                stats[new] = stats.pop(old)\n",
    "            storage.set(key, stats)\n",
    "\n",
    "        features = sorted(features, key=lambda x: (x[-2], x))        \n",
    "        print(line.format(size=len(features), score=score, subspace=','.join(features), **stats), flush=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
